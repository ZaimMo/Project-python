{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtNBZFHO3M7n"
   },
   "source": [
    "# **TikTok Project**\n",
    "**Course 2 - Get Started with Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJCatj3xzrQZ"
   },
   "source": [
    "Welcome to the TikTok Project!\n",
    "\n",
    "You have just started as a data professional at TikTok.\n",
    "\n",
    "The team is still in the early stages of the project. You have received notice that TikTok's leadership team has approved the project proposal. To gain clear insights to prepare for a claims classification model, TikTok's provided data must be examined to begin the process of exploratory data analysis (EDA).\n",
    "\n",
    "A notebook was structured and prepared to help you in this project. Please complete the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgSbVJvomcVa"
   },
   "source": [
    "# **Course 2 End-of-course project: Inspect and analyze data**\n",
    "\n",
    "In this activity, you will examine data provided and prepare it for analysis.\n",
    "<br/>\n",
    "\n",
    "**The purpose** of this project is to investigate and understand the data provided. This activity will:\n",
    "\n",
    "1.   Acquaint you with the data\n",
    "\n",
    "2.   Compile summary information about the data\n",
    "\n",
    "3.   Begin the process of EDA and reveal insights contained in the data\n",
    "\n",
    "4.   Prepare you for more in-depth EDA, hypothesis testing, and statistical analysis\n",
    "\n",
    "**The goal** is to construct a dataframe in Python, perform a cursory inspection of the provided dataset, and inform TikTok data team members of your findings.\n",
    "<br/>\n",
    "*This activity has three parts:*\n",
    "\n",
    "**Part 1:** Understand the situation\n",
    "* How can you best prepare to understand and organize the provided TikTok information?\n",
    "\n",
    "**Part 2:** Understand the data\n",
    "\n",
    "* Create a pandas dataframe for data learning and future exploratory data analysis (EDA) and statistical activities\n",
    "\n",
    "* Compile summary information about the data to inform next steps\n",
    "\n",
    "**Part 3:** Understand the variables\n",
    "\n",
    "* Use insights from your examination of the summary data to guide deeper investigation into variables\n",
    "\n",
    "<br/>\n",
    "\n",
    "To complete the activity, follow the instructions and answer the questions below. Then, you will us your responses to these questions and the questions included in the Course 2 PACE Strategy Document to create an executive summary.\n",
    "\n",
    "Be sure to complete this activity before moving on to Course 3. You can assess your work by comparing the results to a completed exemplar after completing the end-of-course project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjFGokxv2pc5"
   },
   "source": [
    "# **Identify data types and compile summary information**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRUYfzCb4vop"
   },
   "source": [
    "Throughout these project notebooks, you'll see references to the problem-solving framework PACE. The following notebook components are labeled with the respective PACE stage: Plan, Analyze, Construct, and Execute.\n",
    "\n",
    "# **PACE stages**\n",
    "\n",
    "<img src=\"images/Pace.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "   *        [Plan](#scrollTo=psz51YkZVwtN&line=3&uniqifier=1)\n",
    "   *        [Analyze](#scrollTo=mA7Mz_SnI8km&line=4&uniqifier=1)\n",
    "   *        [Construct](#scrollTo=Lca9c8XON8lc&line=2&uniqifier=1)\n",
    "   *        [Execute](#scrollTo=401PgchTPr4E&line=2&uniqifier=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRHb2QQWj99m"
   },
   "source": [
    "<img src=\"images/Plan.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "\n",
    "## **PACE: Plan**\n",
    "\n",
    "Consider the questions in your PACE Strategy Document and those below to craft your response:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TD5rUDqtNoiH"
   },
   "source": [
    "### **Task 1. Understand the situation**\n",
    "\n",
    "*   How can you best prepare to understand and organize the provided information?\n",
    "\n",
    "\n",
    "*Begin by exploring your dataset and consider reviewing the Data Dictionary.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9WkTfMU4_mB"
   },
   "source": [
    "- Identify the columns and their data types.\n",
    "- Check for any missing values or anomalies.\n",
    "- Outline the key variables relevant to the claims classification project.\n",
    "- Develop a structured plan for data analysis and exploratory analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1E9Y5aC0IAA-"
   },
   "source": [
    "<img src=\"images/Analyze.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "## **PACE: Analyze**\n",
    "\n",
    "Consider the questions in your PACE Strategy Document to reflect on the Analyze stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4I-fjg7pNOe4"
   },
   "source": [
    "### **Task 2a. Imports and data loading**\n",
    "\n",
    "Start by importing the packages that you will need to load and explore the dataset. Make sure to use the following import statements:\n",
    "*   `import pandas as pd`\n",
    "\n",
    "*   `import numpy as np`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "I4Jj3QLINOsL"
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJpU5tFvNNDy"
   },
   "source": [
    "Then, load the dataset into a dataframe. Creating a dataframe will help you conduct data manipulation, exploratory data analysis (EDA), and statistical activities.\n",
    "\n",
    "**Note:** As shown in this cell, the dataset has been automatically loaded in for you. You do not need to download the .csv file, or provide more code, in order to access the dataset and proceed with this lab. Please continue with this activity by completing the following instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oYk-rdaWNN4G"
   },
   "outputs": [],
   "source": [
    "# Load dataset into dataframe\n",
    "data = pd.read_csv(\"tiktok_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6KgK-M8o3we"
   },
   "source": [
    "### **Task 2b. Understand the data - Inspect the data**\n",
    "\n",
    "View and inspect summary information about the dataframe by **coding the following:**\n",
    "\n",
    "1. `data.head(10)`\n",
    "2. `data.info()`\n",
    "3. `data.describe()`\n",
    "\n",
    "*Consider the following questions:*\n",
    "\n",
    "**Question 1:** When reviewing the first few rows of the dataframe, what do you observe about the data? What does each row represent?\n",
    "\n",
    "**Question 2:** When reviewing the `data.info()` output, what do you notice about the different variables? Are there any null values? Are all of the variables numeric? Does anything else stand out?\n",
    "\n",
    "**Question 3:** When reviewing the `data.describe()` output, what do you notice about the distributions of each variable? Are there any questionable values? Does it seem that there are outlier values?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "pW7syBEskCS8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    # claim_status    video_id  video_duration_sec  \\\n",
      "0   1        claim  7017666017                  59   \n",
      "1   2        claim  4014381136                  32   \n",
      "2   3        claim  9859838091                  31   \n",
      "3   4        claim  1866847991                  25   \n",
      "4   5        claim  7105231098                  19   \n",
      "5   6        claim  8972200955                  35   \n",
      "6   7        claim  4958886992                  16   \n",
      "7   8        claim  2270982263                  41   \n",
      "8   9        claim  5235769692                  50   \n",
      "9  10        claim  4660861094                  45   \n",
      "\n",
      "                            video_transcription_text verified_status  \\\n",
      "0  someone shared with me that drone deliveries a...    not verified   \n",
      "1  someone shared with me that there are more mic...    not verified   \n",
      "2  someone shared with me that american industria...    not verified   \n",
      "3  someone shared with me that the metro of st. p...    not verified   \n",
      "4  someone shared with me that the number of busi...    not verified   \n",
      "5  someone shared with me that gross domestic pro...    not verified   \n",
      "6  someone shared with me that elvis presley has ...    not verified   \n",
      "7  someone shared with me that the best selling s...    not verified   \n",
      "8  someone shared with me that about half of the ...    not verified   \n",
      "9  someone shared with me that it would take a 50...        verified   \n",
      "\n",
      "  author_ban_status  video_view_count  video_like_count  video_share_count  \\\n",
      "0      under review          343296.0           19425.0              241.0   \n",
      "1            active          140877.0           77355.0            19034.0   \n",
      "2            active          902185.0           97690.0             2858.0   \n",
      "3            active          437506.0          239954.0            34812.0   \n",
      "4            active           56167.0           34987.0             4110.0   \n",
      "5      under review          336647.0          175546.0            62303.0   \n",
      "6            active          750345.0          486192.0           193911.0   \n",
      "7            active          547532.0            1072.0               50.0   \n",
      "8            active           24819.0           10160.0             1050.0   \n",
      "9            active          931587.0          171051.0            67739.0   \n",
      "\n",
      "   video_download_count  video_comment_count  \n",
      "0                   1.0                  0.0  \n",
      "1                1161.0                684.0  \n",
      "2                 833.0                329.0  \n",
      "3                1234.0                584.0  \n",
      "4                 547.0                152.0  \n",
      "5                4293.0               1857.0  \n",
      "6                8616.0               5446.0  \n",
      "7                  22.0                 11.0  \n",
      "8                  53.0                 27.0  \n",
      "9                4104.0               2540.0  \n"
     ]
    }
   ],
   "source": [
    "# Display and examine the first ten rows of the dataframe\n",
    "print(data.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uo90wIjK7z-k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19382 entries, 0 to 19381\n",
      "Data columns (total 12 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   #                         19382 non-null  int64  \n",
      " 1   claim_status              19084 non-null  object \n",
      " 2   video_id                  19382 non-null  int64  \n",
      " 3   video_duration_sec        19382 non-null  int64  \n",
      " 4   video_transcription_text  19084 non-null  object \n",
      " 5   verified_status           19382 non-null  object \n",
      " 6   author_ban_status         19382 non-null  object \n",
      " 7   video_view_count          19084 non-null  float64\n",
      " 8   video_like_count          19084 non-null  float64\n",
      " 9   video_share_count         19084 non-null  float64\n",
      " 10  video_download_count      19084 non-null  float64\n",
      " 11  video_comment_count       19084 non-null  float64\n",
      "dtypes: float64(5), int64(3), object(4)\n",
      "memory usage: 1.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Get summary info\n",
    "print(data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rrdPW1l67zrR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  #      video_id  video_duration_sec  video_view_count  \\\n",
      "count  19382.000000  1.938200e+04        19382.000000      19084.000000   \n",
      "mean    9691.500000  5.627454e+09           32.421732     254708.558688   \n",
      "std     5595.245794  2.536440e+09           16.229967     322893.280814   \n",
      "min        1.000000  1.234959e+09            5.000000         20.000000   \n",
      "25%     4846.250000  3.430417e+09           18.000000       4942.500000   \n",
      "50%     9691.500000  5.618664e+09           32.000000       9954.500000   \n",
      "75%    14536.750000  7.843960e+09           47.000000     504327.000000   \n",
      "max    19382.000000  9.999873e+09           60.000000     999817.000000   \n",
      "\n",
      "       video_like_count  video_share_count  video_download_count  \\\n",
      "count      19084.000000       19084.000000          19084.000000   \n",
      "mean       84304.636030       16735.248323           1049.429627   \n",
      "std       133420.546814       32036.174350           2004.299894   \n",
      "min            0.000000           0.000000              0.000000   \n",
      "25%          810.750000         115.000000              7.000000   \n",
      "50%         3403.500000         717.000000             46.000000   \n",
      "75%       125020.000000       18222.000000           1156.250000   \n",
      "max       657830.000000      256130.000000          14994.000000   \n",
      "\n",
      "       video_comment_count  \n",
      "count         19084.000000  \n",
      "mean            349.312146  \n",
      "std             799.638865  \n",
      "min               0.000000  \n",
      "25%               1.000000  \n",
      "50%               9.000000  \n",
      "75%             292.000000  \n",
      "max            9599.000000  \n"
     ]
    }
   ],
   "source": [
    "# Get summary statistics\n",
    "print(data.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrENd-iQZRdA"
   },
   "source": [
    "Question 1:\n",
    "When reviewing the first few rows of the dataframe, I observe that each row represents an individual TikTok user report. The columns likely include various attributes related to the content, such as user ID, video ID, claim type, timestamps, and possibly the nature of the claims being reported. The first few rows provide a snapshot of these attributes and their values.\n",
    "\n",
    "Question 2:\n",
    "Upon reviewing the data.info() output, I notice several things:\n",
    "\n",
    "The dataframe includes a mix of variable types, such as integers, floats, and objects (strings).\n",
    "There may be some null values present in certain columns, which need to be addressed during analysis.\n",
    "Not all variables are numeric; some are categorical or text-based, which indicates the type of data being captured.\n",
    "The presence of unique identifiers (like user IDs or video IDs) and potential datetime columns for timestamps stand out, as these will be crucial for analysis.\n",
    "Question 3:\n",
    "When reviewing the data.describe() output, I notice the following about the distributions of each variable:\n",
    "\n",
    "The summary statistics (like count, mean, min, max, and standard deviation) provide insight into the central tendency and spread of the numeric variables.\n",
    "There may be questionable values indicated by extremely high or low min/max values that don't align with expectations (e.g., a negative age).\n",
    "The presence of potential outlier values can be identified if there are significant deviations from the mean, as indicated by the standard deviation. These outliers might require further investigation to determine if they are valid or if they should be removed or corrected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYx1emvno7U_"
   },
   "source": [
    "### **Task 2c. Understand the data - Investigate the variables**\n",
    "\n",
    "In this phase, you will begin to investigate the variables more closely to better understand them.\n",
    "\n",
    "You know from the project proposal that the ultimate objective is to use machine learning to classify videos as either claims or opinions. A good first step towards understanding the data might therefore be examining the `claim_status` variable. Begin by determining how many videos there are for each different claim status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Kb8fPcw3rvvo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claim      9608\n",
      "opinion    9476\n",
      "Name: claim_status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# What are the different values for claim status and how many of each are in the data?\n",
    "# Check the unique values in the claim_status column and count the occurrences of each\n",
    "claim_status_counts = data['claim_status'].value_counts()\n",
    "\n",
    "# Display the counts of each claim status\n",
    "print(claim_status_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSE317zdZp1q"
   },
   "source": [
    "**Question:** What do you notice about the values shown?\n",
    "1. Distribution of Claims: The counts for each unique value in claim_status will show you how many videos are classified as claims versus opinions. For example, if there are significantly more videos classified as claims compared to opinions, it indicates that user reports may primarily consist of claims that need to be addressed.\n",
    "\n",
    "2. Imbalance in Classes: If one class (e.g., claims) has a substantially higher count than the other (e.g., opinions), this may indicate an imbalance in the dataset. This imbalance can affect the performance of machine learning models, as models may become biased towards the more frequent class.\n",
    "\n",
    "3. Presence of Other Categories: Depending on the dataset, you might also find other classifications (such as neutral claims or other statuses) that could provide additional context on the nature of the content being reported.\n",
    "\n",
    "4. Potential Data Quality Issues: If you observe unexpected or ambiguous values (like nulls or nonsensical entries), it could point to data quality issues that need to be addressed before analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FpD-nHv5Cpiy"
   },
   "source": [
    "Next, examine the engagement trends associated with each different claim status.\n",
    "\n",
    "Start by using Boolean masking to filter the data according to claim status, then calculate the mean and median view counts for each claim status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "fuwMO66VCri1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average view count for 'claim' status: 501029.4527477102\n"
     ]
    }
   ],
   "source": [
    "# What is the average view count of videos with \"claim\" status?\n",
    "# Calculate the average view count for videos with 'claim' status\n",
    "average_claim_views = data[data['claim_status'] == 'claim']['video_view_count'].mean()\n",
    "\n",
    "# Display the average view count for \"claim\" status\n",
    "print(\"Average view count for 'claim' status:\", average_claim_views)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "FCRPxmpHCrQW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average view count for 'opinion' status: 4956.43224989447\n"
     ]
    }
   ],
   "source": [
    "# What is the average view count of videos with \"opinion\" status?\n",
    "# Calculate the average view count for videos with \"opinion\" status\n",
    "average_opinion_views = data[data['claim_status'] == 'opinion']['video_view_count'].mean()\n",
    "\n",
    "# Display the average view count for \"opinion\" status\n",
    "print(\"Average view count for 'opinion' status:\", average_opinion_views)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zIf6L7cC9be"
   },
   "source": [
    "**Question:** What do you notice about the mean and media within each claim category?\n",
    "1. Significant Difference: There is a significant difference between the average view counts of videos labeled as 'claim' and those labeled as 'opinion.' Videos with a 'claim' status have a much higher average view count compared to those with an 'opinion' status.\n",
    "\n",
    "2. High Engagement for 'Claim' Videos: The high average view count for 'claim' status suggests that these videos may be more engaging or popular among users, possibly because they address more contentious or interesting topics that attract viewers.\n",
    "\n",
    "3. Low Engagement for 'Opinion' Videos: The much lower average view count for 'opinion' status indicates that these videos may not resonate as strongly with the audience, or they may cover topics that are less likely to attract large viewership.\n",
    "\n",
    "4. Potential Outliers: It might be useful to check if there are any outliers in the 'claim' category that could be skewing the average, given the large difference in average view counts.\n",
    "\n",
    "5. Further Analysis Needed: It would be beneficial to analyze other engagement metrics (like likes, shares, and comments) for both categories to understand the overall user interaction and the nature of the content further.\n",
    "\n",
    "Now, examine trends associated with the ban status of the author.\n",
    "\n",
    "Use `groupby()` to calculate how many videos there are for each combination of categories of claim status and author ban status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Luu6W5b7DGtt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  claim_status author_ban_status  video_count\n",
      "0        claim            active         6566\n",
      "1        claim            banned         1439\n",
      "2        claim      under review         1603\n",
      "3      opinion            active         8817\n",
      "4      opinion            banned          196\n",
      "5      opinion      under review          463\n"
     ]
    }
   ],
   "source": [
    "# Get counts for each group combination of claim status and author ban status\n",
    "# Group by 'claim_status' and 'author_ban_status' and count the number of videos in each group\n",
    "ban_status_counts = data.groupby(['claim_status', 'author_ban_status']).size().reset_index(name='video_count')\n",
    "\n",
    "# Display the resulting counts\n",
    "print(ban_status_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWpGkxCTDHlE"
   },
   "source": [
    "**Question:** What do you notice about the number of claims videos with banned authors? Why might this relationship occur?\n",
    "- The data shows that there are 1439 claim video associated witht the banned author, which is a significant number compared to the 196 opinio videos from banned authors. This suggest that banned authors are more likely to create claim videos than opinon videos.\n",
    "- Could be user migh claim againt htis authors due to authors often produce content that ciolets community guidlines or spark controversy.\n",
    "\n",
    "Continue investigating engagement levels, now focusing on `author_ban_status`.\n",
    "\n",
    "Calculate the median video share count of each author ban status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "jaWqtj3yENy0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  author_ban_status  video_share_count\n",
      "0            active              437.0\n",
      "1            banned            14468.0\n",
      "2      under review             9444.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate the median video share count for each author ban status\n",
    "median_share_counts = data.groupby('author_ban_status')['video_share_count'].median().reset_index()\n",
    "\n",
    "# Display the median video share counts for each author ban status\n",
    "print(median_share_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V9eIkY8TENkK"
   },
   "outputs": [],
   "source": [
    "# What's the median video share count of each author ban status?\n",
    "refer line [26]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gLLZObEHEOQf"
   },
   "source": [
    "**Question:** What do you notice about the share count of banned authors, compared to that of active authors? Explore this in more depth.\n",
    "\n",
    "Use `groupby()` to group the data by `author_ban_status`, then use `agg()` to get the count, mean, and median of each of the following columns:\n",
    "* `video_view_count`\n",
    "* `video_like_count`\n",
    "* `video_share_count`\n",
    "\n",
    "Remember, the argument for the `agg()` function is a dictionary whose keys are columns. The values for each column are a list of the calculations you want to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "fVlTvmO-Ebgc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  author_ban_status  video_view_count_count  video_view_count_mean  \\\n",
      "0            active                   15383          215927.039524   \n",
      "1            banned                    1635          445845.439144   \n",
      "2      under review                    2066          392204.836399   \n",
      "\n",
      "   video_view_count_median  video_like_count_count  video_like_count_mean  \\\n",
      "0                   8616.0                   15383           71036.533836   \n",
      "1                 448201.0                    1635          153017.236697   \n",
      "2                 365245.5                    2066          128718.050339   \n",
      "\n",
      "   video_like_count_median  video_share_count_count  video_share_count_mean  \\\n",
      "0                   2222.0                    15383            14111.466164   \n",
      "1                 105573.0                     1635            29998.942508   \n",
      "2                  71204.5                     2066            25774.696999   \n",
      "\n",
      "   video_share_count_median  \n",
      "0                     437.0  \n",
      "1                   14468.0  \n",
      "2                    9444.0  \n"
     ]
    }
   ],
   "source": [
    "# Group by author_ban_status and calculate count, mean, and median for specified columns\n",
    "engagement_stats = data.groupby('author_ban_status').agg(\n",
    "    video_view_count_count=('video_view_count', 'count'),\n",
    "    video_view_count_mean=('video_view_count', 'mean'),\n",
    "    video_view_count_median=('video_view_count', 'median'),\n",
    "    video_like_count_count=('video_like_count', 'count'),\n",
    "    video_like_count_mean=('video_like_count', 'mean'),\n",
    "    video_like_count_median=('video_like_count', 'median'),\n",
    "    video_share_count_count=('video_share_count', 'count'),\n",
    "    video_share_count_mean=('video_share_count', 'mean'),\n",
    "    video_share_count_median=('video_share_count', 'median')\n",
    ").reset_index()\n",
    "\n",
    "# Display the engagement statistics for each author ban status\n",
    "print(engagement_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7R3vKUhEb8_"
   },
   "source": [
    "**Question:** What do you notice about the number of views, likes, and shares for banned authors compared to active authors?\n",
    "\n",
    "Now, create three new columns to help better understand engagement rates:\n",
    "* `likes_per_view`: represents the number of likes divided by the number of views for each video\n",
    "* `comments_per_view`: represents the number of comments divided by the number of views for each video\n",
    "* `shares_per_view`: represents the number of shares divided by the number of views for each video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "eyymCn6oFDP3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  author_ban_status  likes_per_view  comments_per_view  shares_per_view\n",
      "0      under review        0.056584           0.000000         0.000702\n",
      "1            active        0.549096           0.004855         0.135111\n",
      "2            active        0.108282           0.000365         0.003168\n",
      "3            active        0.548459           0.001335         0.079569\n",
      "4            active        0.622910           0.002706         0.073175\n"
     ]
    }
   ],
   "source": [
    "# Create a likes_per_view column\n",
    "# Create a comments_per_view column\n",
    "# Create a shares_per_view column\n",
    "\n",
    "# Create new columns for engagement rates\n",
    "data['likes_per_view'] = data['video_like_count'] / data['video_view_count']\n",
    "data['comments_per_view'] = data['video_comment_count'] / data['video_view_count']\n",
    "data['shares_per_view'] = data['video_share_count'] / data['video_view_count']\n",
    "\n",
    "# Display the updated DataFrame with the new engagement rate columns\n",
    "print(data[['author_ban_status', 'likes_per_view', 'comments_per_view', 'shares_per_view']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y238Q5jaFOwQ"
   },
   "source": [
    "Use `groupby()` to compile the information in each of the three newly created columns for each combination of categories of claim status and author ban status, then use `agg()` to calculate the count, the mean, and the median of each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "WZoK3_-bFPW2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  claim_status author_ban_status  count_likes_per_view  mean_likes_per_view  \\\n",
      "0        claim            active                  6566             0.329542   \n",
      "1        claim            banned                  1439             0.345071   \n",
      "2        claim      under review                  1603             0.327997   \n",
      "3      opinion            active                  8817             0.219744   \n",
      "4      opinion            banned                   196             0.206868   \n",
      "5      opinion      under review                   463             0.226394   \n",
      "\n",
      "   median_likes_per_view  count_comments_per_view  mean_comments_per_view  \\\n",
      "0               0.326538                     6566                0.001393   \n",
      "1               0.358909                     1439                0.001377   \n",
      "2               0.320867                     1603                0.001367   \n",
      "3               0.218330                     8817                0.000517   \n",
      "4               0.198483                      196                0.000434   \n",
      "5               0.228051                      463                0.000536   \n",
      "\n",
      "   median_comments_per_view  count_shares_per_view  mean_shares_per_view  \\\n",
      "0                  0.000776                   6566              0.065456   \n",
      "1                  0.000746                   1439              0.067893   \n",
      "2                  0.000789                   1603              0.065733   \n",
      "3                  0.000252                   8817              0.043729   \n",
      "4                  0.000193                    196              0.040531   \n",
      "5                  0.000293                    463              0.044472   \n",
      "\n",
      "   median_shares_per_view  \n",
      "0                0.049279  \n",
      "1                0.051606  \n",
      "2                0.049967  \n",
      "3                0.032405  \n",
      "4                0.030728  \n",
      "5                0.035027  \n"
     ]
    }
   ],
   "source": [
    "# Group by 'claim_status' and 'author_ban_status', then aggregate the new engagement columns\n",
    "engagement_summary = data.groupby(['claim_status', 'author_ban_status']).agg(\n",
    "    count_likes_per_view=('likes_per_view', 'count'),\n",
    "    mean_likes_per_view=('likes_per_view', 'mean'),\n",
    "    median_likes_per_view=('likes_per_view', 'median'),\n",
    "    count_comments_per_view=('comments_per_view', 'count'),\n",
    "    mean_comments_per_view=('comments_per_view', 'mean'),\n",
    "    median_comments_per_view=('comments_per_view', 'median'),\n",
    "    count_shares_per_view=('shares_per_view', 'count'),\n",
    "    mean_shares_per_view=('shares_per_view', 'mean'),\n",
    "    median_shares_per_view=('shares_per_view', 'median')\n",
    ").reset_index()\n",
    "\n",
    "# Display the summary DataFrame\n",
    "print(engagement_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLhoV4xDFp_o"
   },
   "source": [
    "**Question:**\n",
    "\n",
    "How does the data for claim videos and opinion videos compare or differ? Consider views, comments, likes, and shares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tF_82VLgzrQm"
   },
   "source": [
    "<img src=\"images/Construct.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "## **PACE: Construct**\n",
    "\n",
    "**Note**: The Construct stage does not apply to this workflow. The PACE framework can be adapted to fit the specific requirements of any project.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMHV86A6zrQo"
   },
   "source": [
    "<img src=\"images/Execute.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "## **PACE: Execute**\n",
    "\n",
    "Consider the questions in your PACE Strategy Document and those below to craft your response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3HxcMZgz6iW"
   },
   "source": [
    "### **Given your efforts, what can you summarize for Rosie Mae Bradshaw and the TikTok data team?**\n",
    "\n",
    "*Note for Learners: Your answer should address TikTok's request for a summary that covers the following points:*\n",
    "\n",
    "*   What percentage of the data is comprised of claims and what percentage is comprised of opinions?\n",
    "*   What factors correlate with a video's claim status?\n",
    "*   What factors correlate with a video's engagement level?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HPVfDMum_xYl"
   },
   "source": [
    "==> ENTER YOUR RESPONSE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations!** You've completed this lab. However, you may not notice a green check mark next to this item on Coursera's platform. Please continue your progress regardless of the check mark. Just click on the \"save\" icon at the top of this notebook to ensure your work has been logged."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
